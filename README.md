<div align="left">
  <a href="https://github.com/MiningEmotion/EmotionsMiningPTBR">
  
  ![EmotionMining](https://github.com/MiningEmotion/EmotionsMiningPTBR/assets/171974518/05b49e79-8ca9-4bef-ba26-d633e9719299)
  
  <a/>
  <h1>EmotionsMiningPTBR</h1>

<ul>
  <li><a href="#introducao">Introdu√ß√£o</a></li>
  <li><a href="#conteudos">Conte√∫dos</a></li>
  <ul>
    <li><a href="#tweetemotionptbr">tweetEmotionPTBR.xlsx</a></li>
    <li><a href="#tweetsprocessado">Tweets-processado.xlsx</a></li>
    <li><a href="#fraseschatgpt">frasesChatgpt.xlsx</a></li>
    <li><a href="#emotionminingsvm">EmotionMiningPTBR_SVM.ipynb</a></li>
    <li><a href="#emotionminingsvmbert">bert_multilabel_pytorch_standard.ipynb</a></li>
  </ul>
  <li><a href="#resultados">Resultados</a></li>
  <li><a href="#requirements">Requirements</a></li>

</ul>

<h1></h1>

<h2><a name="introducao">&#x1F4D6 Introdu√ß√£o</a></h2>

<p>‚û• Este reposit√≥rio apresenta scripts de um projeto de pesquisa sobre uma abordagem multirr√≥tulo para a detec√ß√£o de emo√ß√µes expressas em textos curtos em portugu√™s brasileiro. Para isso, prop√µe-se o emprego da roda de emo√ß√µes de Plutchik como ferramenta te√≥rica norteadora √† constru√ß√£o de um corpus rotulado com tweets coletados por Web Scraper. Al√©m disso, s√£o apresentadas as etapas realizadas no pr√©-processamento do corpus e no treinamento de modelos de aprendizado de m√°quina, SVM e BERT, para a classifica√ß√£o emocional de textos gerados por uma LLM.</p>


<h1></h1>

<h2><a name="conteudos">üë®‚Äçüíª Conte√∫dos</a></h2>
<ul type="none">
  <li><h3><a name="tweetemotionptbr">	üóÇÔ∏è tweetEmotionPTBR.xlsx</a></h3></li>
  
<p>‚û• Corpus constru√≠do a partir de publica√ß√µes na rede social X, obtidos por um Web Scraper programado em Python com a biblioteca Selenium. A coleta dos textos foi realizada por meio da busca de sin√¥nimos das emo√ß√µes prim√°rias e secund√°rias. As emo√ß√µes secund√°rias foram identificadas como aquelas que caracterizaram o conjunto de dados como multirr√≥tulo, com base na roda de emo√ß√µes teorizada por Plutchik.</p>

  <li><h3><a name="tweetsprocessado"> üìÅ Tweets-processado.xlsx</a></h3></li>
  

<p>‚û• Corpus tweetEmotionPTBR.xlsx pr√©-processado para o treino e teste do modelo de aprendizagem de m√°quina profundo BERT (Bidirectional Encoder Representations from Transformers).</p>


  <li><h3><a name="fraseschatgpt"> ü§ñ frasesChatgpt.xlsx</a></h3></li>
  

<p>‚û• Dados n√£o vistos gerados com a Large Language Model (LLM) de Intelig√™ncia Artificial (IA) ChatGPT 3.5 para testar os modelos de aprendizado de m√°quina. Foram geradas 10 frases para cada emo√ß√£o secund√°ria, totalizando 80 frases que tiveram por objetivo simular textos curtos que expressem as duas emo√ß√µes prim√°rias que comp√µem a secund√°ria.</p>

  <li><h3><a name="emotionminingsvm">üíª EmotionMiningPTBR_SVM.ipynb</a></h3></li>
  
  Script de treino e teste do modelo m√°quinas de vetores de suporte (Support Vector Machine - SVM). Possiu as importa√ß√µes, leitura e pr√©-processamento do corpus, treino, teste e os resultados do desempenho do modelo na detec√ß√£o de m√∫ltiplas emo√ß√µes em textos curtos.

  <li><h3><a name="emotionminingsvmbert">üñ•Ô∏èbert_multilabel_pytorch_standard.ipynb</a></h3></li>
  
  Script de treino e teste do modelo BERT. Possiu as importa√ß√µes, leitura, treino, teste e os resultados do desempenho do modelo na detec√ß√£o de m√∫ltiplas emo√ß√µes em textos curtos.

</ul>

<h1></h1>

<h2><a name="resultados">üìä Resultados</a></h2>
  
![ComparacaoSVM_BERT](https://github.com/MiningEmotion/EmotionsMiningPTBR/assets/171974518/cbc3c4bf-61b5-4ae4-85d2-b44b9af173ca)

![M√©tricaPorEmo√ß√£o_BERT_SVM](https://github.com/MiningEmotion/EmotionsMiningPTBR/assets/171974518/02839773-021e-42a1-aa0b-1fb2916cbd7b)

<h1></h1>

<h2><a name="requirements">&#x2699 Requirements</a></h2>

<p>‚û• Este projeto requer as seguintes bibliotecas e ferramentas para execu√ß√£o adequada: </p>

~~~Python

joblib==1.1.0
matplotlib==3.7.1
nltk==3.7.1
numpy==1.22.0
pandas==1.4.0
scikit-learn==1.1.0
scikit-multilearn==0.2.0
seaborn==0.12.2
torch==1.10.0
transformers==4.12.2

~~~

<p>‚û• Para instalar todas as depend√™ncias necess√°rias, utilize o comando: 

~~~
pip install -r requirements.txt
~~~
