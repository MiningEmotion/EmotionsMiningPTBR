{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2R7JQdHFGBz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import sys\n",
        "import os\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMlPQF13FF9P"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_excel(\"Tweets-processado.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqhUVSyMFF62"
      },
      "outputs": [],
      "source": [
        "# Removendo colunas inúteis\n",
        "train_df.drop(labels=['UserTags', 'sentimento'], axis=1, inplace=True)\n",
        "\n",
        "# Reorganizando colunas\n",
        "train_df = train_df[['texto', 'alegria', 'tristeza', 'raiva', 'medo',\n",
        "                     'nojo', 'surpresa', 'confianca', 'antecipacao']]\n",
        "\n",
        "target_list = ['alegria', 'tristeza', 'raiva', 'medo',\n",
        "               'nojo', 'surpresa', 'confianca', 'antecipacao']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSjmKyYJIl2M"
      },
      "outputs": [],
      "source": [
        "# Hiperparâmetros\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 1e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATDXZ45xIlyq"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YXXbsj0Iltp"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.title = df['texto']\n",
        "        self.targets = self.df[target_list].values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index])\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxEvHajAOFti"
      },
      "outputs": [],
      "source": [
        "# Dividindo corretamente o dataset em conjunto de treinamento e validação\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.3, random_state=200)\n",
        "\n",
        "# Resetando o índice dos DataFrames\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "\n",
        "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
        "valid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilHjQp6RSnsw"
      },
      "outputs": [],
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRUtQwS5Snqa"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJJkbOuLSnnr",
        "outputId": "c79b15b9-0c09-488c-b601-07eff65a6534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye-qQhzCWglF"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    try:\n",
        "        torch.save(state, checkpoint_path)\n",
        "        if is_best:\n",
        "            torch.save(state, best_model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao salvar o checkpoint: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGw1dRqwSnlK",
        "outputId": "5b0bea83-b646-45e1-89d0-477c0a63c779"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (bert_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        # self.model = AutoModelForPreTraining.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.linear = torch.nn.Linear(768, 8)\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
        "        output = self.bert_model(\n",
        "            input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "        output_dropout = self.dropout(output.pooler_output)\n",
        "        output = self.linear(output_dropout)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R08BB9adUNI4"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuRmU5SXXY2u"
      },
      "outputs": [],
      "source": [
        "val_targets=[]\n",
        "val_outputs=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi_BV9JFt8p-"
      },
      "outputs": [],
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    try:\n",
        "        torch.save(state, checkpoint_path)\n",
        "        if is_best:\n",
        "            torch.save(state, best_model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao salvar o checkpoint: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnY_hBwYn3Zc"
      },
      "outputs": [],
      "source": [
        "def train_model(n_epochs, training_loader, validation_loader, model, optimizer, checkpoint_path, best_model_path):\n",
        "\n",
        "    # Verificar se o diretório existe\n",
        "    if not os.path.exists(os.path.dirname(checkpoint_path)):\n",
        "        os.makedirs(os.path.dirname(checkpoint_path))\n",
        "\n",
        "    # Inicializar o rastreador para a perda mínima de validação\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "\n",
        "        model.train()\n",
        "        print(f'############# Época {epoch}: Início do Treinamento #############')\n",
        "\n",
        "        # Armazenar alvos e previsões de treino\n",
        "        train_targets = []\n",
        "        train_outputs = []\n",
        "\n",
        "        for batch_idx, data in enumerate(training_loader):\n",
        "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
        "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Armazenar alvos e previsões de treino\n",
        "            train_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            train_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "        print(f'############# Época {epoch}: Fim do Treinamento #############')\n",
        "\n",
        "        print(f'############# Época {epoch}: Início da Validação #############')\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        val_targets = []\n",
        "        val_outputs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, data in enumerate(validation_loader):\n",
        "                ids = data['input_ids'].to(device, dtype=torch.long)\n",
        "                mask = data['attention_mask'].to(device, dtype=torch.long)\n",
        "                token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "                targets = data['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "                outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "                loss = loss_fn(outputs, targets)\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "                val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "        print(f'############# Época {epoch}: Fim da Validação #############')\n",
        "\n",
        "        # Calcular perdas médias\n",
        "        if len(training_loader) > 0:\n",
        "            train_loss = train_loss / len(training_loader)\n",
        "        else:\n",
        "            train_loss = float('inf')\n",
        "\n",
        "        if len(validation_loader) > 0:\n",
        "            valid_loss = valid_loss / len(validation_loader)\n",
        "        else:\n",
        "            valid_loss = float('inf')\n",
        "\n",
        "        # Binarizar saídas para cálculos de métricas (assume classificação binária)\n",
        "        train_outputs = np.array(train_outputs) > 0.5\n",
        "        val_outputs = np.array(val_outputs) > 0.5\n",
        "\n",
        "        # Calcular métricas para treino\n",
        "        train_accuracy = accuracy_score(train_targets, train_outputs)\n",
        "        train_precision = precision_score(train_targets, train_outputs, zero_division=0, average='micro')\n",
        "        train_recall = recall_score(train_targets, train_outputs, zero_division=0, average='micro')\n",
        "        train_f1 = f1_score(train_targets, train_outputs, zero_division=0, average='micro')\n",
        "\n",
        "        # Calcular métricas para validação\n",
        "        val_accuracy = accuracy_score(val_targets, val_outputs)\n",
        "        val_precision = precision_score(val_targets, val_outputs, zero_division=0, average='micro')\n",
        "        val_recall = recall_score(val_targets, val_outputs, zero_division=0, average='micro')\n",
        "        val_f1 = f1_score(val_targets, val_outputs, zero_division=0, average='micro')\n",
        "\n",
        "        # Printar estatísticas de treino/validação e métricas\n",
        "        print(f'Época: {epoch} \\tPerda Média de Treinamento: {train_loss:.6f} \\tPerda Média de Validação: {valid_loss:.6f}')\n",
        "        print(f'Métricas de Treino - Acurácia: {train_accuracy:.4f} \\tPrecisão: {train_precision:.4f} \\tRecall: {train_recall:.4f} \\tF1 Score: {train_f1:.4f}')\n",
        "        print(f'Métricas de Validação - Acurácia: {val_accuracy:.4f} \\tPrecisão: {val_precision:.4f} \\tRecall: {val_recall:.4f} \\tF1 Score: {val_f1:.4f}')\n",
        "\n",
        "        # Criar variável de checkpoint e adicionar dados importantes\n",
        "        checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'valid_loss_min': valid_loss,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "        # Salvar checkpoint\n",
        "        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "\n",
        "        # Salvar o modelo se a perda de validação tiver diminuído\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print(f'A perda de validação diminuiu ({valid_loss_min:.6f} --> {valid_loss:.6f}). Salvando o modelo ...')\n",
        "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "        print(f'############# Época {epoch} Concluída #############\\n')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0DIW98gVWlW"
      },
      "outputs": [],
      "source": [
        "ckpt_path = '~/checkpoint.pth'\n",
        "best_model_path = '~/best_model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgD-KcHfVWjS",
        "outputId": "32cd33e4-bfdc-4444-ce36-5510567293cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "############# Época 1: Início do Treinamento #############\n",
            "############# Época 1: Fim do Treinamento #############\n",
            "############# Época 1: Início da Validação #############\n",
            "############# Época 1: Fim da Validação #############\n",
            "Época: 1 \tPerda Média de Treinamento: 0.472363 \tPerda Média de Validação: 0.354923\n",
            "Métricas de Treino - Acurácia: 0.0294 \tPrecisão: 0.4503 \tRecall: 0.0574 \tF1 Score: 0.1018\n",
            "Métricas de Validação - Acurácia: 0.2279 \tPrecisão: 0.9321 \tRecall: 0.3212 \tF1 Score: 0.4778\n",
            "A perda de validação diminuiu (inf --> 0.354923). Salvando o modelo ...\n",
            "############# Época 1 Concluída #############\n",
            "\n",
            "############# Época 2: Início do Treinamento #############\n",
            "############# Época 2: Fim do Treinamento #############\n",
            "############# Época 2: Início da Validação #############\n",
            "############# Época 2: Fim da Validação #############\n",
            "Época: 2 \tPerda Média de Treinamento: 0.252803 \tPerda Média de Validação: 0.174266\n",
            "Métricas de Treino - Acurácia: 0.5911 \tPrecisão: 0.9496 \tRecall: 0.6793 \tF1 Score: 0.7920\n",
            "Métricas de Validação - Acurácia: 0.7815 \tPrecisão: 0.9469 \tRecall: 0.8405 \tF1 Score: 0.8905\n",
            "A perda de validação diminuiu (0.354923 --> 0.174266). Salvando o modelo ...\n",
            "############# Época 2 Concluída #############\n",
            "\n",
            "############# Época 3: Início do Treinamento #############\n",
            "############# Época 3: Fim do Treinamento #############\n",
            "############# Época 3: Início da Validação #############\n",
            "############# Época 3: Fim da Validação #############\n",
            "Época: 3 \tPerda Média de Treinamento: 0.147912 \tPerda Média de Validação: 0.123608\n",
            "Métricas de Treino - Acurácia: 0.8252 \tPrecisão: 0.9510 \tRecall: 0.8726 \tF1 Score: 0.9101\n",
            "Métricas de Validação - Acurácia: 0.8570 \tPrecisão: 0.9492 \tRecall: 0.8905 \tF1 Score: 0.9189\n",
            "A perda de validação diminuiu (0.174266 --> 0.123608). Salvando o modelo ...\n",
            "############# Época 3 Concluída #############\n",
            "\n",
            "############# Época 4: Início do Treinamento #############\n",
            "############# Época 4: Fim do Treinamento #############\n",
            "############# Época 4: Início da Validação #############\n",
            "############# Época 4: Fim da Validação #############\n",
            "Época: 4 \tPerda Média de Treinamento: 0.104901 \tPerda Média de Validação: 0.102319\n",
            "Métricas de Treino - Acurácia: 0.8815 \tPrecisão: 0.9586 \tRecall: 0.9161 \tF1 Score: 0.9369\n",
            "Métricas de Validação - Acurácia: 0.8951 \tPrecisão: 0.9399 \tRecall: 0.9233 \tF1 Score: 0.9315\n",
            "A perda de validação diminuiu (0.123608 --> 0.102319). Salvando o modelo ...\n",
            "############# Época 4 Concluída #############\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, ckpt_path, best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW7BeLwGWm9I"
      },
      "outputs": [],
      "source": [
        "# Carregar os dados de teste\n",
        "test_df = pd.read_excel(\"FrasesChatgpt.xlsx\")\n",
        "\n",
        "# Remover colunas inúteis dos dados de teste\n",
        "test_df.drop(labels=['sentimento'], axis=1, inplace=True)\n",
        "\n",
        "# Reorganizar colunas\n",
        "test_df = test_df[['texto', 'alegria', 'tristeza', 'raiva', 'medo',\n",
        "                   'nojo', 'surpresa', 'confianca', 'antecipacao']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B7BY1hoYWTb"
      },
      "outputs": [],
      "source": [
        "# Criar dataset e dataloader para o conjunto de teste\n",
        "test_dataset = CustomDataset(test_df, tokenizer, MAX_LEN)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Uo21WnYdUZ",
        "outputId": "09527f8c-8e0d-41fc-876c-e3465a0a890c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (bert_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Função para carregar o melhor modelo salvo\n",
        "def load_best_model(model, best_model_path):\n",
        "    checkpoint = torch.load(best_model_path)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    return model\n",
        "\n",
        "# Carregar o melhor modelo\n",
        "best_model = BERTClass()\n",
        "best_model = load_best_model(best_model, best_model_path)\n",
        "best_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOzREfWXYiHJ"
      },
      "outputs": [],
      "source": [
        "# Avaliar o modelo no conjunto de teste\n",
        "def evaluate_model(test_loader, model):\n",
        "    model.eval()\n",
        "    test_targets = []\n",
        "    test_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(test_loader):\n",
        "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
        "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            test_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            test_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "    test_outputs = np.array(test_outputs) > 0.5\n",
        "\n",
        "    accuracy = accuracy_score(test_targets, test_outputs)\n",
        "    precision = precision_score(test_targets, test_outputs, zero_division=0, average='micro')\n",
        "    recall = recall_score(test_targets, test_outputs, zero_division=0, average='micro')\n",
        "    f1 = f1_score(test_targets, test_outputs, zero_division=0, average='micro')\n",
        "\n",
        "    print(f'Acurácia no conjunto de teste: {accuracy:.4f}')\n",
        "    print(f'Precisão no conjunto de teste: {precision:.4f}')\n",
        "    print(f'Recall no conjunto de teste: {recall:.4f}')\n",
        "    print(f'F1 Score no conjunto de teste: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6eK2lKYYkOJ",
        "outputId": "2660c60e-c5d3-47b2-fe2b-c76aca428144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de teste: 0.3875\n",
            "Precisão no conjunto de teste: 0.7000\n",
            "Recall no conjunto de teste: 0.4843\n",
            "F1 Score no conjunto de teste: 0.5725\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(test_data_loader, best_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxCWz2a1u3a5"
      },
      "outputs": [],
      "source": [
        "def predict(model, data_loader):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "            mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
        "            target = batch['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "            output = model(ids, mask, token_type_ids)\n",
        "            outputs.extend(torch.sigmoid(output).cpu().detach().numpy().tolist())\n",
        "            targets.extend(target.cpu().detach().numpy().tolist())\n",
        "\n",
        "    return outputs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whRO8NXan5ye",
        "outputId": "33a58122-9ef6-4dca-de37-22860f1022da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métricas para a emoção 'alegria':\n",
            "Acurácia: 0.6000\n",
            "Precisão: 0.3636\n",
            "Recall: 0.8000\n",
            "F1 Score: 0.5000\n",
            "\n",
            "\n",
            "Métricas para a emoção 'tristeza':\n",
            "Acurácia: 0.8750\n",
            "Precisão: 1.0000\n",
            "Recall: 0.5000\n",
            "F1 Score: 0.6667\n",
            "\n",
            "\n",
            "Métricas para a emoção 'raiva':\n",
            "Acurácia: 0.7625\n",
            "Precisão: 1.0000\n",
            "Recall: 0.0500\n",
            "F1 Score: 0.0952\n",
            "\n",
            "\n",
            "Métricas para a emoção 'medo':\n",
            "Acurácia: 0.9625\n",
            "Precisão: 1.0000\n",
            "Recall: 0.8500\n",
            "F1 Score: 0.9189\n",
            "\n",
            "\n",
            "Métricas para a emoção 'nojo':\n",
            "Acurácia: 0.9000\n",
            "Precisão: 1.0000\n",
            "Recall: 0.6000\n",
            "F1 Score: 0.7500\n",
            "\n",
            "\n",
            "Métricas para a emoção 'surpresa':\n",
            "Acurácia: 0.8750\n",
            "Precisão: 1.0000\n",
            "Recall: 0.5000\n",
            "F1 Score: 0.6667\n",
            "\n",
            "\n",
            "Métricas para a emoção 'confianca':\n",
            "Acurácia: 0.8000\n",
            "Precisão: 0.6429\n",
            "Recall: 0.4500\n",
            "F1 Score: 0.5294\n",
            "\n",
            "\n",
            "Métricas para a emoção 'antecipacao':\n",
            "Acurácia: 0.7875\n",
            "Precisão: 1.0000\n",
            "Recall: 0.1053\n",
            "F1 Score: 0.1905\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Realizar previsões no conjunto de dados de teste\n",
        "test_outputs, test_targets = predict(best_model, test_data_loader)\n",
        "\n",
        "# Converter as previsões e os rótulos verdadeiros em arrays binários\n",
        "test_outputs_bin = np.array(test_outputs) > 0.5\n",
        "test_targets_bin = np.array(test_targets)\n",
        "\n",
        "# Nomes das colunas de emoção (ajuste conforme necessário)\n",
        "emotion_columns = ['alegria', 'tristeza', 'raiva', 'medo', 'nojo', 'surpresa', 'confianca', 'antecipacao']\n",
        "\n",
        "# Converter previsões e rótulos verdadeiros para DataFrames\n",
        "df_prediction = pd.DataFrame(test_outputs_bin, columns=emotion_columns)\n",
        "df_true_labels = pd.DataFrame(test_targets_bin, columns=emotion_columns)\n",
        "\n",
        "# Calcular métricas para cada emoção\n",
        "for column in emotion_columns:\n",
        "    accuracy = accuracy_score(df_true_labels[column], df_prediction[column])\n",
        "    precision = precision_score(df_true_labels[column], df_prediction[column])\n",
        "    recall = recall_score(df_true_labels[column], df_prediction[column])\n",
        "    f1 = f1_score(df_true_labels[column], df_prediction[column])\n",
        "\n",
        "    print(f\"Métricas para a emoção '{column}':\")\n",
        "    print(f\"Acurácia: {accuracy:.4f}\")\n",
        "    print(f\"Precisão: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
